{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pshthwdj0sT_",
        "cruujxpn36TW",
        "1siPUQk54I7L",
        "t-g-d1pB4M8v",
        "OexHPRTs4f8b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Establishing Pipelines"
      ],
      "metadata": {
        "id": "uBNx_B8hz-_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I have the structure of the transformations that I am going to apply to the data, I will create pipelines to facilitate the processes"
      ],
      "metadata": {
        "id": "VvcZ5MIm1CL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data separation"
      ],
      "metadata": {
        "id": "pshthwdj0sT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the data\n",
        "route_employee_survey = '/content/drive/MyDrive/workplace-engineering-take-home-test-main/src/employee_survey_data.csv'\n",
        "route_general_data = '/content/drive/MyDrive/workplace-engineering-take-home-test-main/src/general_data.csv'\n",
        "route_manager_survey = '/content/drive/MyDrive/workplace-engineering-take-home-test-main/src/manager_survey_data.csv'\n",
        "\n",
        "# Transform data into DataFrame\n",
        "employee_survey = pd.read_csv(route_employee_survey, index_col=\"EmployeeID\")\n",
        "general_data = pd.read_csv(route_general_data, index_col=\"EmployeeID\")\n",
        "manager_survey = pd.read_csv(route_manager_survey, index_col=\"EmployeeID\")\n",
        "\n",
        "# Merge regular data sources into one dataframe\n",
        "data = employee_survey.merge(general_data, on='EmployeeID')\n",
        "data = data.merge(manager_survey, on='EmployeeID')\n",
        "\n",
        "# Drop rows with null values of attrition\n",
        "data.Regular = data.Regular.dropna(subset=['Attrition'])\n",
        "\n",
        "# Separate target from predictors\n",
        "y = data.Regular.Attrition\n",
        "X = data.drop([('Regular', 'Attrition')], axis=1)\n",
        "\n",
        "# Select numerical columns\n",
        "columns_numerical = X.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Select categorical columns\n",
        "columns_categorical = X.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "# For Ordinal Encoding\n",
        "columns_ordinal = [\"BusinessTravel\", \"MaritalStatus\", \"Gender\", \"Over18\"]\n",
        "\n",
        "#For OneHot Encoding\n",
        "columns_one_hot = columns_categorical.drop(columns_ordinal)\n",
        "\n",
        "# Select numerical columns except TotalWorkingYears\n",
        "data_int_cols = columns_numerical.drop(\"TotalWorkingYears\")"
      ],
      "metadata": {
        "id": "VNv9JFiQ0KlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Preprocesing steps"
      ],
      "metadata": {
        "id": "cruujxpn36TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical imputation"
      ],
      "metadata": {
        "id": "1siPUQk54I7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a custom transformer for using with TotalWorkingYears column"
      ],
      "metadata": {
        "id": "n6XFCJYRgQir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "class WorkingYearsTransformer:\n",
        "    def __init__(self):\n",
        "        self.gen_imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "    def fit(self, X, Y=None):\n",
        "        self.gen_imputer.fit(X[data_int_cols])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        transformed_df = df.copy()\n",
        "\n",
        "        transformed_df[data_int_cols] = self.gen_imputer.transform(df[data_int_cols])\n",
        "        transformed_df.loc[transformed_df.TotalWorkingYears.isna(), \"TotalWorkingYears\"] = transformed_df.loc[transformed_df.TotalWorkingYears.isna(), \"YearsAtCompany\"]\n",
        "\n",
        "        return transformed_df.to_numpy()\n",
        "\n",
        "numerical_transformer = WorkingYearsTransformer()"
      ],
      "metadata": {
        "id": "_F3filZDgNQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical imputation and encoding"
      ],
      "metadata": {
        "id": "t-g-d1pB4M8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputer for categorical columns\n",
        "\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')"
      ],
      "metadata": {
        "id": "n_HHniO550B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing for categorical Ordinal data"
      ],
      "metadata": {
        "id": "_LeGl_Bi6RyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Encoder for marital status, travel frequency and over 18.\n",
        "ordinal_encoder_travel = OrdinalEncoder(\n",
        "    categories=[np.array(['Non-Travel', 'Travel_Rarely', 'Travel_Frequently'])],\n",
        "    handle_unknown='use_encoded_value',\n",
        "    unknown_value=-1\n",
        "    )\n",
        "ordinal_encoder_marital = OrdinalEncoder(\n",
        "    categories=[np.array(['Single', 'Married', 'Divorced'])],\n",
        "    handle_unknown='use_encoded_value',\n",
        "    unknown_value=-1\n",
        "    )\n",
        "ordinal_encoder_18 = OrdinalEncoder(\n",
        "    categories=[np.array(['N', 'Y'])],\n",
        "    handle_unknown='use_encoded_value',\n",
        "    unknown_value=-1\n",
        "    )"
      ],
      "metadata": {
        "id": "adpH2T350KqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A custom transformer for ordinal categorical data to distinguish between the columns BusinessTravel, MaritalStatus and Over18"
      ],
      "metadata": {
        "id": "qMCyVIZeEfz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Categorical_Ordinal_Transformer:\n",
        "    def __init__(self):\n",
        "        self.temp_imputer = SimpleImputer(strategy='most_frequent')\n",
        "        self.ordinal_encoder_travel = ordinal_encoder_travel\n",
        "        self.ordinal_encoder_marital = ordinal_encoder_marital\n",
        "        self.ordinal_encoder_gender = OrdinalEncoder()\n",
        "        self.ordinal_encoder_18 = ordinal_encoder_18\n",
        "\n",
        "    def fit(self, X, Y=None):\n",
        "        imputed_X = X[columns_ordinal].copy()\n",
        "\n",
        "        self.temp_imputer.fit(imputed_X)\n",
        "\n",
        "        imputed_X.iloc[:, :] = self.temp_imputer.transform(imputed_X)\n",
        "\n",
        "        self.ordinal_encoder_travel.fit(imputed_X[[\"BusinessTravel\"]])\n",
        "        self.ordinal_encoder_marital.fit(imputed_X[[\"MaritalStatus\"]])\n",
        "        self.ordinal_encoder_gender.fit(imputed_X[[\"Gender\"]])\n",
        "        self.ordinal_encoder_18.fit(imputed_X[[\"Over18\"]])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        transformed_df = df[columns_ordinal].copy()\n",
        "\n",
        "        transformed_df.iloc[:, :] = self.temp_imputer.transform(transformed_df)\n",
        "\n",
        "        transformed_df.loc[:, \"BusinessTravel\"] = self.ordinal_encoder_travel.transform(transformed_df[[\"BusinessTravel\"]])\n",
        "        transformed_df.loc[:, \"MaritalStatus\"] = self.ordinal_encoder_marital.transform(transformed_df[[\"MaritalStatus\"]])\n",
        "        transformed_df.loc[:, \"Gender\"] = self.ordinal_encoder_gender.transform(transformed_df[[\"Gender\"]])\n",
        "        transformed_df.loc[:, \"Over18\"] = self.ordinal_encoder_18.transform(transformed_df[[\"Over18\"]])\n",
        "\n",
        "        return transformed_df\n",
        "\n",
        "\n",
        "categorical_ordinal_transformer = Categorical_Ordinal_Transformer()"
      ],
      "metadata": {
        "id": "5KGs1t447P1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing for categorical not Ordinal data"
      ],
      "metadata": {
        "id": "iAkWUrS-6f2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "onehot_encoder = OneHotEncoder(\n",
        "    handle_unknown='infrequent_if_exist',\n",
        "    sparse_output=False,\n",
        "    )\n",
        "\n",
        "categorical_oneHot_transformer = Pipeline(steps=[\n",
        "    ('imputer', cat_imputer),\n",
        "    ('oneHot', onehot_encoder)\n",
        "])"
      ],
      "metadata": {
        "id": "H9AKszpq6d51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordinal and OneHot separation"
      ],
      "metadata": {
        "id": "kqCJzjL46-QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Needed a custom transformer here to manage the loss of the columns for the inner transformer"
      ],
      "metadata": {
        "id": "IEMZqDlPy037"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocesor_Transformer:\n",
        "    def __init__(self):\n",
        "        self.categorical_ordinal_transformer = categorical_ordinal_transformer\n",
        "        self.categorical_oneHot_transformer = categorical_oneHot_transformer\n",
        "\n",
        "    def fit(self, X, Y=None):\n",
        "        ordinal_df = X[columns_ordinal]\n",
        "        oneHot_df = X[columns_one_hot]\n",
        "\n",
        "        self.categorical_ordinal_transformer = self.categorical_ordinal_transformer.fit(ordinal_df)\n",
        "        self.categorical_oneHot_transformer = self.categorical_oneHot_transformer.fit(oneHot_df)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        transformed_df = df.copy()\n",
        "\n",
        "        transformed_df.loc[:, columns_ordinal] = self.categorical_ordinal_transformer.transform(transformed_df[columns_ordinal])\n",
        "\n",
        "        hot_encoded_data = self.categorical_oneHot_transformer.transform(transformed_df[columns_one_hot])\n",
        "        hot_encoded_columns = categorical_oneHot_transformer.get_feature_names_out()\n",
        "\n",
        "        hot_encoded_df = pd.DataFrame(hot_encoded_data, columns=hot_encoded_columns, index=transformed_df.index)\n",
        "        transformed_df = pd.concat([transformed_df[columns_ordinal], hot_encoded_df], axis=1)\n",
        "\n",
        "        return transformed_df\n",
        "\n",
        "\n",
        "categorical_transformer = Preprocesor_Transformer()"
      ],
      "metadata": {
        "id": "sd3lAQFAFdND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical and Numerical separation"
      ],
      "metadata": {
        "id": "OexHPRTs4f8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same as before"
      ],
      "metadata": {
        "id": "EHg5In8KzTwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cat_Num_Separator:\n",
        "    def __init__(self):\n",
        "        self.numerical_transformer = numerical_transformer\n",
        "        self.categorical_transformer = categorical_transformer\n",
        "\n",
        "    def fit(self, X, Y=None):\n",
        "        num_df = X[columns_numerical]\n",
        "        cat_df = X[columns_categorical]\n",
        "\n",
        "        self.numerical_transformer = self.numerical_transformer.fit(num_df)\n",
        "        self.categorical_transformer = self.categorical_transformer.fit(cat_df)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        num_vals = self.numerical_transformer.transform(df[columns_numerical])\n",
        "        cat_vals = self.categorical_transformer.transform(df[columns_categorical])\n",
        "\n",
        "        return num_vals.merge(cat_vals, on=\"EmployeeID\")\n",
        "\n",
        "\n",
        "catNumSeparator = Cat_Num_Separator()"
      ],
      "metadata": {
        "id": "_r6nqyGy2fVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}